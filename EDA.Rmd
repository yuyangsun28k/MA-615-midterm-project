---
title: "eda"
author: "thomas"
date: "2023-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
library(lubridate)
library(stringr)
library(plotly)
library(maps)
library(reshape2)
```

## Data Upload

### Import NOAA Data

```{r}
# Import Datasets from NOAA
detail2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_details-ftp_v1.0_d2020_c20230927.csv")
detail2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_details-ftp_v1.0_d2021_c20231017.csv")
location2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_locations-ftp_v1.0_d2020_c20231017.csv")
location2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_locations-ftp_v1.0_d2021_c20231017.csv")
fata2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_fatalities-ftp_v1.0_d2020_c20230927.csv")
fata2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_fatalities-ftp_v1.0_d2021_c20231017.csv")

```

#### Merge detail2020 ,fata 2020 and location2020; detail2021, fata 2021 and location2021

```{r}
# Validate keys
if(any(duplicated(detail2020$EVENT_ID)) | any(duplicated(detail2021$EVENT_ID))) {
  stop("Duplicate EVENT_IDs found in detail datasets.")
}

# Pre-process datasets (if necessary, based on your analysis needs)

# Merge in steps
combinedDetails <- rbind(detail2020, detail2021)
combinedLocations <- rbind(location2020, location2021)
combinedFatalities <- rbind(fata2020, fata2021)

combined <- merge(combinedDetails, combinedLocations, by = c("EVENT_ID", "EPISODE_ID"), all = TRUE)
combined <- merge(combined, combinedFatalities, by = "EVENT_ID", all.x = TRUE)

# Post-process merged dataset
combined <- combined[!duplicated(combined$EVENT_ID), ]

# Consistency check (based on your analysis needs)

# Define the types of floods to filter
floodTypes <- c("Flood", "Coastal Flood", "Flash Flood", "Lakeshore Flood")

# Filter for Flood events
combined <- combined[combined$EVENT_TYPE %in% floodTypes, ]

# Get unique incidents of flood and print them
unique_incidents <- unique(combined$EVENT_TYPE)
print(unique_incidents)

```

#### Clean NOAA Data
```{r}
#colnames(combined)
combined <- combined[, -which(names(combined) %in% c("WFO", "CZ_TIMEZONE", "SOURCE","TOR_WIDTH", "TOR_LENGTH", "TOR_OTHER_CZ_FIPS", "TOR_OTHER_CZ_NAME", "TOR_OTHER_CZ_STATE", "TOR_F_SCALE","CZ_TYPE","CZ_FIPS","CZ_NAME","EVENT_NARRATIVE","EPISODE_NARRATIVE","END_AZIMUTH","END_RANGE","BEGIN_RANGE","BEGIN_AZIMUTH","LAT2","LON2","RANGE","AZIMUTH","LOCATION_INDEX","MAGNITUDE_TYPE","MAGNITUDE","STATE_FLIPS"))]
colnames(combined)
```

##### Check how dengerous flood is
```{r}
dangerousflood <- combined[, c("EVENT_ID", "EPISODE_ID", "STATE", "YEAR", "MONTH_NAME", "EVENT_TYPE","INJURIES_DIRECT", "INJURIES_INDIRECT", "DEATHS_DIRECT", "DEATHS_INDIRECT",  "DAMAGE_PROPERTY", "DAMAGE_CROPS", "FLOOD_CAUSE", "CATEGORY","BEGIN_LOCATION", "END_LOCATION", "LATITUDE", "LONGITUDE","FATALITY_AGE", "FATALITY_SEX", "FATALITY_LOCATION","BEGIN_DATE_TIME")]

# Convert BEGIN_DATE_TIME to Date format
dangerousflood$BEGIN_DATE <- as.Date(dangerousflood$BEGIN_DATE_TIME, format = "%d-%b-%y %H:%M:%S")

# Check the first few dates to ensure they were converted correctly
head(dangerousflood$BEGIN_DATE)

```

### Import census data

```{r}
#census 5225
meta2020_1_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2020.S1701-Column-Metadata.csv")
meta2020_2_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2020.S1701-Data.csv", skip = 1)
meta2021_1_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2021.S1701-Column-Metadata.csv")
meta2021_2_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2021.S1701-Data.csv")

#census 0133
meta2020_1_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2020.DP05-Column-Metadata.csv")
meta2020_2_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2020.DP05-Data.csv")
meta2021_1_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2021.DP05-Column-Metadata.csv")
meta2021_2_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2021.DP05-Data.csv")

#census 0147
meta2020_1_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2020.B25001-Column-Metadata.csv")
meta2020_2_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2020.B25001-Data.csv")
meta2021_1_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2021.B25001-Column-Metadata.csv")
meta2021_2_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2021.B25001-Data.csv")
```

#### Edit census data 5225
```{r}

```


### Import FEMA datasets

```{r}
#Import Datasets from FEMA v1
data_url <- "https://www.fema.gov/api/open/v1/FemaWebDisasterSummaries.json"

# Making the GET request to the data URL
response <- GET(url = data_url)

# Check the response status code
print(status_code(response))

# Parse the content of the response into a dataframe
data <- fromJSON(rawToChar(response$content))

# Convert the data to a dataframe
floodv1 <- as.data.frame(data$FemaWebDisasterSummaries)

```

```{r}
# Import Datasets from FEMA v2
# Correctly encode the URL
data_url <- "https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.json?$filter=incidentType%20eq%20%27Flood%27%20and%20(incidentBeginDate%20ge%20%272020-01-01T00:00:00.000Z%27%20and%20incidentBeginDate%20le%20%272021-12-31T23:59:59.000Z%27)"

# Making the GET request to the data URL
response <- GET(url = data_url)

# Check the response status code
print(status_code(response))

# Parse the content of the response into a dataframe
data <- fromJSON(rawToChar(response$content))

# Convert the data to a dataframe
floodv2 <- as.data.frame(data$DisasterDeclarationsSummaries)

# Check the unique values in the incidentType column
unique_incidents <- unique(floodv2$incidentType)

# Print the unique incident types
print(unique_incidents)

```
#### Merge FEMA datasets
```{r}
combinedFEMA <- floodv1 %>%
  inner_join(floodv2, by = "disasterNumber")
```

## Deep cleaning NOAA

### Glimpse
```{r}
# glimpse
glimpse(dangerousflood)
```
### States counts

```{r}
# Check all states
state_all <- dangerousflood |> group_by(STATE) |> count()
# if(sum(state_all$n) == dim(dangerousflood)[1])
  {print("Every row has value in the State column.")}
print(state_all)
# The most counts of states
state_max <- state_all$STATE[which(state_all$n ==  max(state_all$n)  )]
print(state_max)
# Group by STATE and count the number of occurrences
state_all <- dangerousflood %>% 
  group_by(STATE) %>% 
  summarise(Count= n())
# Top counts of states
top_states <- state_all %>% 
  top_n(5, Count)
print(top_states)

```
### State vs damage
```{r warning=FALSE}
# Function to convert damage values to numeric
convert_damage_to_numeric <- function(damage) {
  # Remove any characters that are not digits or decimal points
  damage <- gsub("[^0-9.]", "", as.character(damage))
  # Convert to numeric
  as.numeric(damage)
}

# Clean DAMAGE_PROPERTY and DAMAGE_CROPS columns
dangerousflood$DAMAGE_PROPERTY <- convert_damage_to_numeric(dangerousflood$DAMAGE_PROPERTY)
dangerousflood$DAMAGE_CROPS <- convert_damage_to_numeric(dangerousflood$DAMAGE_CROPS)

# Now, summarize the total damage by state
state_damage <- dangerousflood %>%
  group_by(STATE) %>%
  summarise(Total_Damage_Property = sum(DAMAGE_PROPERTY, na.rm = TRUE),
            Total_Damage_Crops = sum(DAMAGE_CROPS, na.rm = TRUE))

# View the warnings from the last summarise operation
dplyr::last_dplyr_warnings()
state_damage <- dangerousflood %>%
  group_by(STATE) %>%
  summarise(Total_Damage_Property = sum(as.numeric(DAMAGE_PROPERTY), na.rm = TRUE),
            Total_Damage_Crops = sum(as.numeric(DAMAGE_CROPS), na.rm = TRUE))

#total property damage
ggplot(state_damage, aes(x = reorder(STATE, -Total_Damage_Property), y = Total_Damage_Property)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Total Property Damage by State",
       x = "State",
       y = "Total Property Damage") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Log transform of total crop damage
ggplot(state_damage, aes(x = reorder(STATE, -Total_Damage_Crops), y = log(Total_Damage_Crops + 1))) +
  geom_bar(stat = "identity", fill = "cyan4") +
  labs(title = "Log of Total Crop Damage by State",
       x = "State",
       y = "Log of Total Crop Damage") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Total Property Damage in a map visual
# Get US map data
states_map <- map_data("state")

# Aggregate total property damages by state
state_damage_totals <- dangerousflood %>%
  group_by(STATE) %>%
  summarise(Total_Damage_Property = sum(DAMAGE_PROPERTY, na.rm = TRUE)) %>%
  mutate(STATE = tolower(STATE)) # Ensure state names match map data

# Merge map data with total property damages
map_data_merged <- merge(states_map, state_damage_totals, by.x = "region", by.y = "STATE", all.x = TRUE)

# Plot
ggplot() +
  geom_polygon(data = map_data_merged, aes(x = long, y = lat, group = group, fill = Total_Damage_Property), color = "white") +
  scale_fill_continuous(low = "white", high = "red", na.value = "grey50", name = "Total Property Damage") +
  labs(title = "Total Property Damage by State") +
  theme_void() +
  theme(legend.position = "right")


# Aggregate total crop damages by state
state_crop_damage_totals <- dangerousflood %>%
  group_by(STATE) %>%
  summarise(Total_Damage_Crops = sum(DAMAGE_CROPS, na.rm = TRUE)) %>%
  mutate(STATE = tolower(STATE)) # Ensure state names match map data

# Merge map data with total crop damages
map_data_merged_crops <- merge(states_map, state_crop_damage_totals, by.x = "region", by.y = "STATE", all.x = TRUE)

# Plot for Total Crop Damage with adjusted color scale and legend
ggplot() +
  geom_polygon(data = map_data_merged_crops, aes(x = long, y = lat, group = group, fill = Total_Damage_Crops), color = "white") +
  scale_fill_continuous(name = "Total Crop Damage", 
                        trans = "log1p", # Log transformation to better visualize the range
                        low = "lightgreen", high = "darkgreen", 
                        na.value = "grey50", # Grey color for states with NA values
                        breaks = scales::trans_breaks("log1p", function(x) 10^x), # Adjust breaks for log scale
                        labels = scales::trans_format("log1p", scales::math_format(10^.x))) + # Adjust labels for log scale
  labs(title = "Total Crop Damage by State") +
  theme_void() +
  theme(legend.position = "right",
        legend.key.width = unit(1.5, "cm"), # Adjust legend key width
        legend.title = element_text(size = 10), # Adjust legend title size
        legend.text = element_text(size = 8)) # Adjust legend text size

```



### Injuries & Deaths
```{r}
# Summarize death counts by state
death_counts_by_state <- dangerousflood %>%
  group_by(STATE) %>%
  summarise(Total_Deaths = sum(DEATHS_DIRECT + DEATHS_INDIRECT))

# Summarize injury counts by state
injury_counts_by_state <- dangerousflood %>%
  group_by(STATE) %>%
  summarise(Total_Injuries = sum(INJURIES_DIRECT + INJURIES_INDIRECT))

# Base plot with death counts in green
p_combined <- plot_ly(death_counts_by_state, x = ~reorder(STATE, -Total_Deaths), y = ~Total_Deaths, type = 'bar', marker = list(color = 'green'), name = 'Deaths') %>%
  layout(title = "Total Counts Due to Floods by State",
         xaxis = list(title = "State", tickangle = 45),
         yaxis = list(title = "Total Counts"))

# Add injury counts to the same plot in blue
p_combined <- p_combined %>%
  add_trace(data = injury_counts_by_state, x = ~reorder(STATE, -Total_Injuries), y = ~Total_Injuries, type = 'bar', marker = list(color = 'blue'), name = 'Injuries')

# Render the combined plot
p_combined


```

```{r}
# Convert BEGIN_DATE_TIME to Date format
dangerousflood$BEGIN_DATE <- as.Date(dangerousflood$BEGIN_DATE_TIME, format = "%d-%b-%y %H:%M:%S")

# Aggregate injuries and deaths by date
injuries_deaths_by_date <- dangerousflood %>%
  group_by(BEGIN_DATE) %>%
  summarise(Total_Injuries = sum(INJURIES_DIRECT + INJURIES_INDIRECT),
            Total_Deaths = sum(DEATHS_DIRECT + DEATHS_INDIRECT))

# Time Series Line Plot of Total Injuries Over Time
p_injuries <- plot_ly(data = injuries_deaths_by_date, x = ~BEGIN_DATE, y = ~Total_Injuries, type = 'scatter', mode = 'lines', line = list(color = 'cyan4'), name = 'Injuries') %>%
  layout(title = "Time Series of Total Injuries & Deaths Over Time",
         xaxis = list(title = "Date"),
         yaxis = list(title = "Total Injuries"))

# Time Series Line Plot of Total Deaths Over Time
p_deaths <- plot_ly(data = injuries_deaths_by_date, x = ~BEGIN_DATE, y = ~Total_Deaths, type = 'scatter', mode = 'lines', line = list(color = 'red'), name = 'Deaths') %>%
  layout(title = "Time Series of Total Injuries & Deaths Over Time",
         xaxis = list(title = "Date"),
         yaxis = list(title = "Total Deaths"))

# Arrange the plots in a grid
subplot(p_injuries, p_deaths, nrows = 2, shareX = TRUE, titleX = FALSE)

```

---
title: "eda"
author: "thomas"
date: "2023-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
library(lubridate)
```

## Data cleaning

### Import NOAA Data

```{r}
# Import Datasets from NOAA
detail2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_details-ftp_v1.0_d2020_c20230927.csv")
detail2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_details-ftp_v1.0_d2021_c20231017.csv")
location2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_locations-ftp_v1.0_d2020_c20231017.csv")
location2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_locations-ftp_v1.0_d2021_c20231017.csv")
fata2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_fatalities-ftp_v1.0_d2020_c20230927.csv")
fata2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_fatalities-ftp_v1.0_d2021_c20231017.csv")

```

#### Merge detail2020 ,fata 2020 and location2020; detail2021, fata 2021 and location2021

```{r}
# Validate keys
if(any(duplicated(detail2020$EVENT_ID)) | any(duplicated(detail2021$EVENT_ID))) {
  stop("Duplicate EVENT_IDs found in detail datasets.")
}

# Pre-process datasets (if necessary, based on your analysis needs)

# Merge in steps
combinedDetails <- rbind(detail2020, detail2021)
combinedLocations <- rbind(location2020, location2021)
combinedFatalities <- rbind(fata2020, fata2021)

combined <- merge(combinedDetails, combinedLocations, by = c("EVENT_ID", "EPISODE_ID"), all = TRUE)
combined <- merge(combined, combinedFatalities, by = "EVENT_ID", all.x = TRUE)

# Post-process merged dataset
combined <- combined[!duplicated(combined$EVENT_ID), ]

# Consistency check (based on your analysis needs)

# Define the types of floods to filter
floodTypes <- c("Flood", "Coastal Flood", "Flash Flood", "Lakeshore Flood")

# Filter for Flood events
combined <- combined[combined$EVENT_TYPE %in% floodTypes, ]

# Get unique incidents of flood and print them
unique_incidents <- unique(combined$EVENT_TYPE)
print(unique_incidents)

```

#### Clean NOAA Data
```{r}
#colnames(combined)
combined <- combined[, -which(names(combined) %in% c("WFO", "CZ_TIMEZONE", "SOURCE","TOR_WIDTH", "TOR_LENGTH", "TOR_OTHER_CZ_FIPS", "TOR_OTHER_CZ_NAME", "TOR_OTHER_CZ_STATE", "TOR_F_SCALE","CZ_TYPE","CZ_FIPS","CZ_NAME","EVENT_NARRATIVE","EPISODE_NARRATIVE","END_AZIMUTH","END_RANGE","BEGIN_RANGE","BEGIN_AZIMUTH","LAT2","LON2","RANGE","AZIMUTH","LOCATION_INDEX","MAGNITUDE_TYPE","MAGNITUDE","STATE_FLIPS"))]
colnames(combined)
```

##### Check how dengerous flood is
```{r}
dangerousflood <- combined[, c("EVENT_ID", "EPISODE_ID", "STATE", "YEAR", "MONTH_NAME", "EVENT_TYPE","INJURIES_DIRECT", "INJURIES_INDIRECT", "DEATHS_DIRECT", "DEATHS_INDIRECT",  "DAMAGE_PROPERTY", "DAMAGE_CROPS", "FLOOD_CAUSE", "CATEGORY","BEGIN_LOCATION", "END_LOCATION", "LATITUDE", "LONGITUDE","FATALITY_AGE", "FATALITY_SEX", "FATALITY_LOCATION")]
head(dangerousflood)
```

### Import census data

```{r}
#census 5225
meta2020_1_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2020.S1701-Column-Metadata.csv")
meta2020_2_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2020.S1701-Data.csv", skip = 1)
meta2021_1_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2021.S1701-Column-Metadata.csv")
meta2021_2_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2021.S1701-Data.csv")

#census 0133
meta2020_1_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2020.DP05-Column-Metadata.csv")
meta2020_2_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2020.DP05-Data.csv")
meta2021_1_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2021.DP05-Column-Metadata.csv")
meta2021_2_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2021.DP05-Data.csv")

#census 0147
meta2020_1_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2020.B25001-Column-Metadata.csv")
meta2020_2_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2020.B25001-Data.csv")
meta2021_1_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2021.B25001-Column-Metadata.csv")
meta2021_2_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2021.B25001-Data.csv")
```

#### Edit census data 5225
```{r}

```


### Import FEMA datasets

```{r}
#Import Datasets from FEMA v1
data_url <- "https://www.fema.gov/api/open/v1/FemaWebDisasterSummaries.json"

# Making the GET request to the data URL
response <- GET(url = data_url)

# Check the response status code
print(status_code(response))

# Parse the content of the response into a dataframe
data <- fromJSON(rawToChar(response$content))

# Convert the data to a dataframe
floodv1 <- as.data.frame(data$FemaWebDisasterSummaries)

```

```{r}
# Import Datasets from FEMA v2
# Correctly encode the URL
data_url <- "https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.json?$filter=incidentType%20eq%20%27Flood%27%20and%20(incidentBeginDate%20ge%20%272020-01-01T00:00:00.000Z%27%20and%20incidentBeginDate%20le%20%272021-12-31T23:59:59.000Z%27)"

# Making the GET request to the data URL
response <- GET(url = data_url)

# Check the response status code
print(status_code(response))

# Parse the content of the response into a dataframe
data <- fromJSON(rawToChar(response$content))

# Convert the data to a dataframe
floodv2 <- as.data.frame(data$DisasterDeclarationsSummaries)

# Check the unique values in the incidentType column
unique_incidents <- unique(floodv2$incidentType)

# Print the unique incident types
print(unique_incidents)

```
#### Merge FEMA datasets
```{r}
combinedFEMA <- floodv1 %>%
  inner_join(floodv2, by = "disasterNumber")
```


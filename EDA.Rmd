---
title: "eda"
author: "thomas"
date: "2023-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(httr)
library(jsonlite)
```

## EDA
## Import Datasets

```{r}
# Import Datasets from NOAA
detail2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_details-ftp_v1.0_d2020_c20230927.csv")
detail2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_details-ftp_v1.0_d2021_c20231017.csv")
location2020 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_locations-ftp_v1.0_d2020_c20231017.csv")
location2021 <- read.csv("/Users/thomas/Downloads/ma615/midterm/NOAA/StormEvents_locations-ftp_v1.0_d2021_c20231017.csv")

# Filter EVENT_TYPE to flood for detail2021, detail2020
detail2020 <- detail2020[detail2020$EVENT_TYPE == "Flood", ]
detail2021 <- detail2021[detail2021$EVENT_TYPE == "Flood", ]

# Check the unique values in the incidentType column
unique_incidents1 <- unique(floodv1$incidentType)
unique_incidents2 <- unique(floodv1$incidentType)

# Print the unique incident types
print(unique_incidents1)
print(unique_incidents2)
```


```{r}
#Import Datasets from FEMA v1
data_url <- "https://www.fema.gov/api/open/v1/DisasterDeclarationsSummaries.json"

# Making the GET request to the data URL
response <- GET(url = data_url)

# Check the response status code
print(status_code(response))

# Parse the content of the response into a dataframe
data <- fromJSON(rawToChar(response$content))

# Convert the data to a dataframe
df1 <- as.data.frame(data$DisasterDeclarationsSummaries)
floodv1 <- df1[df1$incidentType == "Flood", ]

# Display the first few rows of the dataframe
head(df1)

# Display the first few rows of the dataframe
head(floodv1)

# Check the unique values in the incidentType column
unique_incidents <- unique(floodv1$incidentType)

# Print the unique incident types
print(unique_incidents)

```


```{r}
#Import Datasets from FEMA v2
data_url <- "https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.json"

# Making the GET request to the data URL
response <- GET(url = data_url)

# Check the response status code
print(status_code(response))

# Parse the content of the response into a dataframe
data <- fromJSON(rawToChar(response$content))

# Convert the data to a dataframe
df2 <- as.data.frame(data$DisasterDeclarationsSummaries)
floodv2 <- df2[df2$incidentType == "Flood", ]

# Display the first few rows of the dataframe
head(floodv2)

# Check the unique values in the incidentType column
unique_incidents <- unique(floodv2$incidentType)

# Print the unique incident types
print(unique_incidents)

```


## Data Cleaning

```{r}
# List all columns in the dataset
namefloodv1 <- names(floodv1)
namefloodv2 <- names(floodv2)
namedetail2020 <- names(detail2020)
namedetail2021 <- names(detail2021)
namelocation2020 <- names(location2020)
namelocation2021 <- names(location2021)

# Print the column names
# Print column names for each dataset
print(namefloodv1)
print(namefloodv2)
print(namedetail2020)
print(namedetail2021)
print(namelocation2020)
print(namelocation2021)

```
## Merge detail2020 and location2020; detail2021 and location2021
```{r}
# Merge the datasets 2020
combined2020 <- merge(detail2020, location2020, by = c("EVENT_ID", "EPISODE_ID"))

# Check the first few rows of the combined dataset
head(combined2020)

# Merge the datasets 2021
combined2021 <- merge(detail2021, location2021, by = c("EVENT_ID", "EPISODE_ID"))

# Check the first few rows of the combined dataset
head(combined2021)

# Combine the datasets for 2020 and 2021
combinedNOAA <- rbind(combined2020, combined2021)
```

```{r}
# Merge the datasets using 'disasterNumber'
combinedFEMA <- merge(floodv1, floodv2, by = "disasterNumber")
```

## Merge into one single dataset

```{r}
# Check the first few rows of the combined dataset
head(combinedNOAA)
head(combinedFEMA)
```
## Import census data
```{r}
#census 5225
meta2020_1_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2020.S1701-Column-Metadata.csv")
meta2020_2_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2020.S1701-Data.csv")
meta2021_1_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2021.S1701-Column-Metadata.csv")
meta2021_2_5225 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T135225/ACSST5Y2021.S1701-Data.csv")

#census 0133
meta2020_1_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2020.DP05-Column-Metadata.csv")
meta2020_2_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2020.DP05-Data.csv")
meta2021_1_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2021.DP05-Column-Metadata.csv")
meta2021_2_0133 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140133/ACSDP5Y2021.DP05-Data.csv")

#census 0147
meta2020_1_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2020.B25001-Column-Metadata.csv")
meta2020_2_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2020.B25001-Data.csv")
meta2021_1_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2021.B25001-Column-Metadata.csv")
meta2021_2_0147 <- read.csv("/Users/thomas/Downloads/ma615/midterm/Census Download_2023-10-23T140147/ACSDT5Y2021.B25001-Data.csv")
```


